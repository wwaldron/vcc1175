{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5f23f2-be22-4ffb-965f-f4e97b15b696",
   "metadata": {},
   "source": [
    "# VCC 1175 - Photometry Checker\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> This notebook should be run with the <span style=\"font-family: 'Ariel', monospace;\">stenv</span> environment\n",
    "    where the <span style=\"font-family: 'Ariel', monospace;\">regions</span> package has been added if not in the current\n",
    "    version of <span style=\"font-family: 'Ariel', monospace;\">stenv</span>.\n",
    "</div>\n",
    "\n",
    "This notebook is designed to check the photometry between the Hubble Pipeline DRCs and\n",
    "this pipeline's DRCs. Predominantly, this checks for *systematic* offsets in the data. That is,\n",
    "some individual sources may have high offset due to differences in how CRs are processed, but most\n",
    "sources should exhibit low difference in the measured photometry.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Note that this notebook depends on a\n",
    "[DS9](https://sites.google.com/cfa.harvard.edu/saoimageds9/home) region file\n",
    "called `../DS9/PhotometryCheckerSources.reg` to be present to run.\n",
    "This region file should define a set of sources (using any region that defines a center such\n",
    "as a point or a circle) that will have their photometry compared between this pipeline and the\n",
    "*HST* pipeline. For simplicity, this could be a symbolic link to the region file created by the\n",
    "[GAIA Notebook](../../../../Data/GAIA/GAIA_Downloader.ipynb).\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95efa829-8f3f-4dea-b845-9740d841adbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import iglob\n",
    "\n",
    "# 3rd Party Imports\n",
    "import numpy as np\n",
    "\n",
    "# Astropy Imports\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "import photutils as phot\n",
    "import regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f9f72-6964-4ecd-86a0-c89450ac4def",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98228e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Directory\n",
    "if Path.cwd().name != \"PythonNotebooks\":\n",
    "    if Path.cwd().name == \"Notebooks\":\n",
    "        os.chdir(\"../Images/ProcessedImages/HST/PythonNotebooks\")\n",
    "    else:\n",
    "        raise RuntimeError(\"This notebook must be run from the NED directory.\")\n",
    "print(f'Current Directory: {Path.cwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3103842-12c1-484b-a7db-00f6acc40a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "TOP_LVL_DIR = Path('../../../../').resolve()\n",
    "IMG_DIR     = TOP_LVL_DIR / 'Images'\n",
    "MAST_DIR    = IMG_DIR / 'mastDownload/HST'\n",
    "PROC_DIR    = IMG_DIR / 'ProcessedImages/HST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717cafbf-968b-4a82-9cf9-6907e4d753bd",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "### Load HST Pipeline Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af18df-91d3-4765-bb6e-03710bcac013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load HST DRCs\n",
    "hstData = {}\n",
    "for fn in MAST_DIR.rglob('*dr?.fits'):\n",
    "\n",
    "    # Open the file to get the filter\n",
    "    with fits.open(fn) as hduList:\n",
    "        hdr = hduList[0].header  # Get the Header\n",
    "        if 'FILTER' in hdr:      # If the FILTER keyword exists (WFC3)\n",
    "            filt = hdr['FILTER']\n",
    "        elif 'CLEAR' not in hdr['FILTER1']:  # If FILTER1 is not clear (ACS)\n",
    "            filt = hdr['FILTER1']\n",
    "        else:                                # Else FILTER2 must be the filter (ACS)\n",
    "            filt = hdr['FILTER2']\n",
    "\n",
    "        # Store the Name using the filter as the dict key\n",
    "        # Start the Empty List if Key does not exist\n",
    "        if filt not in hstData:\n",
    "            hstData[filt] = {}\n",
    "\n",
    "        # Load the Image Data and WCS\n",
    "        hstData[filt]['img'] = hduList[1].data\n",
    "        hstData[filt]['wcs'] = WCS(hduList[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f5ed4-d5f2-42c9-a06b-71af64b25b40",
   "metadata": {},
   "source": [
    "### Load My Pipeline Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b4907-9013-406c-b592-8df643c6a056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load My DRCs\n",
    "myData = {}\n",
    "for fn in PROC_DIR.rglob('*dr?_irn.fits'):  # May need to change glob if NaN Inpainter Skipped\n",
    "\n",
    "    # Open the file to get the filter\n",
    "    with fits.open(fn) as hduList:\n",
    "        hdr = hduList[0].header  # Get the Header\n",
    "        if 'FILTER' in hdr:      # If the FILTER keyword exists (WFC3)\n",
    "            filt = hdr['FILTER']\n",
    "        elif 'CLEAR' not in hdr['FILTER1']:  # If FILTER1 is not clear (ACS)\n",
    "            filt = hdr['FILTER1']\n",
    "        else:                                # Else FILTER2 must be the filter (ACS)\n",
    "            filt = hdr['FILTER2']\n",
    "\n",
    "        # Store the Name using the filter as the dict key\n",
    "        # Start the Empty List if Key does not exist\n",
    "        if filt not in myData:\n",
    "            myData[filt] = {}\n",
    "\n",
    "        # Load the Image Data and WCS\n",
    "        myData[filt]['img'] = hduList[1].data\n",
    "        myData[filt]['wcs'] = WCS(hduList[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1671809-6e3a-4034-bf9a-a2d37f14b25b",
   "metadata": {},
   "source": [
    "### Load Region Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf1a2b-2a7f-4460-90ed-670e8afb6faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Regions Data\n",
    "ds9Regs = regions.Regions.read(PROC_DIR / 'DS9' / 'PhotometryCheckerSources.reg')\n",
    "\n",
    "# Convert Centers to SkyCoord Array\n",
    "srcCrds = SkyCoord([reg.center for reg in ds9Regs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e250b3-3f49-4faa-bd77-6417e2e25797",
   "metadata": {},
   "source": [
    "## Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd18065-2195-446a-8bf2-780d4f340750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Radii\n",
    "R_IN  = 0.5 * u.arcsec\n",
    "R_OUT = 0.9 * u.arcsec\n",
    "\n",
    "# Area\n",
    "A_IN  = np.pi*R_IN**2\n",
    "A_OUT = np.pi*(R_OUT**2 - R_IN**2)\n",
    "\n",
    "# Setup Apertures\n",
    "aper = phot.aperture.SkyCircularAperture(srcCrds, R_IN)\n",
    "annu = phot.aperture.SkyCircularAnnulus(srcCrds, R_IN, R_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7afab-0a3b-415f-935b-7160cc38d2fd",
   "metadata": {},
   "source": [
    "### Simple Aperture Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd954fb-f493-49ea-ac96-b09a018747ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through HST Data\n",
    "for dataDict in hstData.values():\n",
    "\n",
    "    # Get Photometry\n",
    "    aperRes = phot.aperture.aperture_photometry(\n",
    "        dataDict['img'],\n",
    "        aper,\n",
    "        wcs=dataDict['wcs']\n",
    "    )\n",
    "    annuRes = phot.aperture.aperture_photometry(\n",
    "        dataDict['img'],\n",
    "        annu,\n",
    "        wcs=dataDict['wcs']\n",
    "    )\n",
    "\n",
    "    # Store Results\n",
    "    dataDict['flux'] = aperRes['aperture_sum'] - annuRes['aperture_sum']*(A_IN/A_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f1468-4840-4614-977f-06ad69df0b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through My Data\n",
    "for dataDict in myData.values():\n",
    "\n",
    "    # Get Photometry\n",
    "    aperRes = phot.aperture.aperture_photometry(\n",
    "        dataDict['img'],\n",
    "        aper,\n",
    "        wcs=dataDict['wcs']\n",
    "    )\n",
    "    annuRes = phot.aperture.aperture_photometry(\n",
    "        dataDict['img'],\n",
    "        annu,\n",
    "        wcs=dataDict['wcs']\n",
    "    )\n",
    "\n",
    "    # Store Results\n",
    "    dataDict['flux'] = aperRes['aperture_sum'] - annuRes['aperture_sum']*(A_IN/A_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through Filters\n",
    "for filt in hstData:\n",
    "\n",
    "    # Print\n",
    "    print(filt)\n",
    "    display(\n",
    "        (hstData[filt]['flux'] - myData[filt]['flux'])/hstData[filt]['flux'] << u.percent\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
